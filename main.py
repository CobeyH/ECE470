# -*- coding: utf-8 -*-
"""ECE 470 Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YvLUO-sRl9zvoD3Gopa3TuhANIVAwLYu

# ECE 470: House Price Predictions

Cobey Hollier V00893715 \
Kutay Cinar V00886983 \
Chris Dunn V00897180 \
Emmanuel Ayodele V00849004

##Pre Work
"""

# Basic Stuff
import sys
import math
import numpy as np 
import pandas as pd 
import sklearn as sk
import tensorflow as tf

# Plotting
import seaborn as sns
from scipy import stats
from matplotlib import pyplot as plt

# Neural Networks
from keras.optimizers import SGD
from keras import regularizers
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
import torchvision.transforms as transforms 
from torch.utils.data.sampler import SubsetRandomSampler # Sampler 

# Trees
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn import ensemble
from sklearn.datasets import load_iris
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import GradientBoostingRegressor

print ('Python version: {}'.format(sys.version))

showImage = input("\nDisplay result figures? (yes or no)\n")

# ------------------
#  ECE 470 Project 
# ------------------

train = pd.read_csv('train.csv')

# ------------------
#  Data Cleaning
# ------------------

def print_results(trainLabel, trainPredictions, validationLabel, validationPredictions, validationData, model):
  print('Results:')
  print("- Training error:", round(mean_squared_error(trainLabel, trainPredictions, squared=False), 1))
  print("- Validation error:", round(mean_squared_error(validationLabel, validationPredictions, squared=False), 1))
  print("- Score:", round(model.score(validationData, validationLabel)*100,5), "%")

def print_section_separator():
    print('\n//////////////////////////////\n')

def getAverageHousePrice(priceList1, priceList2):
  priceSum = 0
  for price in priceList1:
    priceSum += price
  for price in priceList2:
    priceSum += price
  return priceSum / (len(priceList1) + len(priceList2))

# Get dummy data
dummifiedDataframe = pd.get_dummies(train)
# Split data into test and validation
trainDf, validationDf = train_test_split(dummifiedDataframe, test_size=0.15, shuffle=True)
labelFeature = "SalePrice"

# Split the data and label into different dataframes
trainRealSalePrice = trainDf[labelFeature]
trainData = trainDf.drop([labelFeature], axis=1)
validationRealSalePrice = validationDf[labelFeature]
validationData = validationDf.drop([labelFeature], axis=1)

"""## Heat Map"""

# Heat map for showing correlation between features
plt.figure(figsize=(15, 13))
sns.heatmap(train.corr())

"""##Decision Tree"""

print('\n#-----------------------------#')
print("#        Decision Tree        #")
print('#-----------------------------#')

decisionTreeRegressor = tree.DecisionTreeRegressor(criterion="mse", random_state=0, max_depth=10)

# train tree
print("\nTraining Decision Tree: This may take a while.\n")
decisionTree = decisionTreeRegressor.fit(trainData, trainRealSalePrice)

# predict values
validationPredictions = decisionTree.predict(validationData)
trainPredictions = decisionTree.predict(trainData)

# Print Final Results
print_results(trainRealSalePrice, trainPredictions, validationRealSalePrice, validationPredictions, validationData, decisionTree)
print("- Maximum tree depth:", decisionTree.tree_.max_depth)

# Max depth scores 
scores = []

# Code to determine which max depth is best
for i in range(1,16):

    decisionTreeRegressor = tree.DecisionTreeRegressor(criterion="mse", random_state=0, max_depth=i)

    # train tree
    decisionTree = decisionTreeRegressor.fit(trainData, trainRealSalePrice)

    # predict values
    validationPredictions = decisionTree.predict(validationData)
    trainPredictions = decisionTree.predict(trainData)

    scores.append(round(decisionTree.score(validationData, validationRealSalePrice)*100,5))

print("\nScore for decision trees of depth 1 to 15")
print(scores)

Depths = np.arange(15) + 1

plt.figure(figsize=(10, 10))

rank = [int((max(scores)-elem)*len(scores)*0.75/(max(scores)+1)) for elem in scores] 
pal = sns.color_palette("Reds_r",len(scores))
sns.set(style="whitegrid", color_codes=True)

sns.scatterplot(x=Depths, y=scores, hue=scores, palette=pal, legend=False)

"""Plotting Graphs"""

# Plot first 20 samples predictions and real values for the decision tree.
plt.figure(figsize=(15, 10))

# Make x and y labels bigger
plt.rc('xtick', labelsize=15) 
plt.rc('ytick', labelsize=15)

size = 20
X = np.arange(size) + 1
plt.xticks(np.arange(min(X), max(X)+1, 1.0))

# Plot bars
plt.bar(X + 0.00, validationRealSalePrice[:size], color = 'b', width = 0.25)
plt.bar(X + 0.25, validationPredictions[:size], color = 'g', width = 0.25)

# Add legend
plt.legend(labels=['Real house price', 'Estimated sale price'], prop={'size': 16})

if showImage == 'yes':
  plt.show()

print_section_separator()

"""##Random Forest"""

print('#-----------------------------#')
print("#        Random Forest        #")
print('#-----------------------------#')

# RandomForestRegressor = ensemble.RandomForestRegressor(n_estimators=500, max_depth=15)

# # train tree
# print("\nTraining Random Forest: This should take around a minute.")
# randomForest = RandomForestRegressor.fit(trainData, trainRealSalePrice)

# # predict values
# trainForestPrediction = randomForest.predict(trainData)
# validationForestPrediction = randomForest.predict(validationData)

# # Print Results
# print_results(trainRealSalePrice, trainForestPrediction, validationRealSalePrice, validationForestPrediction, validationData, randomForest)

# print_section_separator()

"""##Gradient Boosted Trees"""

# print('#--------------------------------------#')
# print("#        Gradient Boosted Trees        #")
# print('#--------------------------------------#')

# GradientBoostingRegressor = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.015, max_depth=6, random_state=0)

# # train tree
# print("\nTraining Gradient Boosting: This make take a while")
# gradientBoosted = GradientBoostingRegressor.fit(trainData, trainRealSalePrice)

# # predict values
# trainGBTPrediction = gradientBoosted.predict(trainData)
# validationGBTPrediction = gradientBoosted.predict(validationData)

# # Print Results
# print_results(trainRealSalePrice, trainGBTPrediction, validationRealSalePrice, validationGBTPrediction, validationData, gradientBoosted)

# print_section_separator()

"""##K-Nearest Neighbour"""

# print('#--------------------------------------#')
# print("#         K-Nearest Neighbour          #")
# print('#--------------------------------------#')

# # K-Nearest Neighbour didn't make it into the final report due to it producing very poor results. However, the code is still here in case you are curious.
# neigh = KNeighborsRegressor(n_neighbors=15)

# # Train
# print("\nTraining K-Nearest Neighbour: This make take a while")
# nearestNeigh = neigh.fit(trainData, trainRealSalePrice)

# # Predict values
# validationNearestNeigh = neigh.predict(validationData)
# trainNearestNeigh = neigh.predict(trainData)

# # Print Results
# print_results(trainRealSalePrice, trainNearestNeigh, validationRealSalePrice, validationNearestNeigh, validationData, nearestNeigh)

# print_section_separator()

# --------------------
#    Neural Network
# --------------------

print('#------------------------------#')
print("#        Neural Network        #")
print('#------------------------------#')

# Create model
neuralNetwork = Sequential()
neuralNetwork.add(Dense(305, input_dim=305, kernel_initializer='normal', activation='relu'))
neuralNetwork.add(Dense(100, kernel_initializer='normal', activation='relu'))
neuralNetwork.add(Dense(10, kernel_initializer='normal', activation='relu'))
neuralNetwork.add(Dense(1, kernel_initializer='normal', activation='relu'))

# Compile model
neuralNetwork.compile(loss='mean_squared_error', optimizer='adam')

# Fit model
print("\nTraining Neural Network: This may take some time\n")
neuralNetwork.fit(trainData, trainRealSalePrice, epochs=2000, verbose=1)

# Predict values
validationResults = neuralNetwork.evaluate(validationData, validationRealSalePrice)
trainResults = neuralNetwork.evaluate(trainData, trainRealSalePrice)

# # Print Results
print("Results")
print('- Training error:', math.sqrt(trainResults))
print('- Validation error:', math.sqrt(validationResults))
print('- Score:', (round(1 - (math.sqrt(validationResults)/getAverageHousePrice(trainRealSalePrice, validationRealSalePrice)), 5)*100), '%')
print()
